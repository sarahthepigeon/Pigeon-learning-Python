Day 20: Embeddings

你好Sarah！

什么是embedding？这是一种把任何信息（文字/图片）map成向量的方式。当所有东西都变成一个固定维度（比如2048维）的向量后，我们就可以通过任意两个向量的欧几里得距离，或者是点乘，知道这两个向量的相似程度，从而知晓embedding之前的文字/图片在语义上的相关程度。

You may wonder 这是如何做到的？这涉及到一点点机器学习（我瞎猜的）：

	方法1：autoencoder

	我们通过CNN（卷积神经网络）/RNN（循环神经网络）或者Transformer，作为编码器，将文字/图片编码，即，将文字/图片转成一个固定维度的向量，然后通过另一组几乎镜像的结构，将这个向量重建为原始的文字/图片。

	但是这样做是无法准确还原出原始信息的，因为仅仅2048维度的向量是无法精确表示大段文字或者是一张图片的，所以这其中必须涉及到有损压缩。

	一开始这个autoencoder是随机初始化的，会把图片压缩成一个nonsense的向量，然后重建出来的信息完全与原始信息不符，但是我们可以以原始信息和重建信息的difference作为损失函数，然后对网络进行训练/梯度下降，这会让原始信息和重建信息越来越接近，而这其中的bottle neck - embedded向量 - 也会变得有意义起来

---

	方法2：对比学习

	（懒得写了嘿嘿嘿）

	Claude：
	
	对比学习是一种通过"比较"来学习数据表示的方法：

	**核心思想**：让相似的样本在特征空间中靠近，不相似的样本远离

	**基本步骤**：
	1. 构造正样本对（相似）和负样本对（不相似）
	2. 用神经网络编码样本特征
	3. 训练模型拉近正样本，推远负样本

	**主要优势**：
	- 不需要大量标注数据
	- 学到的特征泛化性好
	- 适用于图像、文本等多种数据

	**典型应用**：图像识别预训练、文本相似度计算、推荐系统等

	简单来说，对比学习就是让机器通过"这个像那个，但不像另一个"的方式来理解数据。

总之，请你学习如何调用openai的API，将任意文字/图片转成embedding，然后将其转为numpy array。试着将两个自定义的字符串embed成向量，然后点乘查看向量的相似程度。应该会很好玩吧哈哈哈哈

加油Sarah！！！